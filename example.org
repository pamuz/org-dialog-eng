#+TITLE: Example Dialog Engineering Document
#+AI_SYSTEM: You are a helpful programming assistant who provides clear, concise answers.
#+AI_MODEL: claude-sonnet-4
#+AI_COMMAND: claude

* Introduction to Dialog Engineering

This document demonstrates how to use org-ai-prompt-mode to have interactive
conversations with AI tools directly within your org-mode documents.

* Python Data Processing Example

I'm working on a Python script to process data from a CSV file.

#+BEGIN_SRC python
import csv

def process_data(filename):
    with open(filename, 'r') as f:
        reader = csv.reader(f)
        data = list(reader)
    return data
#+END_SRC

#+BEGIN_PROMPT
Can you help me add error handling to this function? I want to handle:
1. File not found errors
2. CSV parsing errors
3. Empty files
#+END_PROMPT

#+BEGIN_RESPONSE
Here's an improved version with comprehensive error handling:

```python
import csv
import os

def process_data(filename):
    # Check if file exists
    if not os.path.exists(filename):
        raise FileNotFoundError(f"File '{filename}' not found")

    try:
        with open(filename, 'r') as f:
            reader = csv.reader(f)
            data = list(reader)

            # Check for empty file
            if not data:
                raise ValueError(f"File '{filename}' is empty")

            return data
    except csv.Error as e:
        raise ValueError(f"Error parsing CSV file: {e}")
    except Exception as e:
        raise RuntimeError(f"Unexpected error processing file: {e}")
```

Key improvements:
1. **File existence check**: Uses `os.path.exists()` before opening
2. **CSV parsing errors**: Catches `csv.Error` exceptions
3. **Empty file check**: Validates that data was actually read
4. **General error handling**: Catches unexpected errors with proper context
#+END_RESPONSE

* Follow-up Questions

Great! Now I'd like to add logging to track what's happening.

#+BEGIN_PROMPT
Can you add logging to the process_data function? I want to log:
- When we start processing a file
- If any errors occur
- When processing completes successfully
#+END_PROMPT

* Testing Examples

** Unit Testing

#+BEGIN_PROMPT
Can you write unit tests for the process_data function using pytest?
Include tests for all the error cases we discussed.
#+END_PROMPT

** Integration Testing

#+BEGIN_PROMPT
What would be a good integration test strategy for this CSV processing code?
#+END_PROMPT

* JavaScript Example

Let me switch to a different programming language.

#+BEGIN_SRC javascript
function fetchUserData(userId) {
    return fetch(`/api/users/${userId}`)
        .then(response => response.json());
}
#+END_SRC

#+BEGIN_PROMPT
This function doesn't handle errors. Can you add proper error handling
for network errors, HTTP errors, and JSON parsing errors?
#+END_PROMPT

* Notes About This Workflow

The beauty of this approach is that:

1. **Context is preserved**: Each prompt has access to all previous conversation
2. **Documentation included**: Your notes and code are right alongside the AI responses
3. **Branching conversations**: You can re-execute earlier prompts to explore different paths
4. **Version control friendly**: Everything is in plain text, works great with git

** How to Use

1. Enable org-ai-prompt-mode in your org buffer
2. Write your notes, code, and questions
3. Add a #+BEGIN_PROMPT block with your question
4. Position cursor in the PROMPT block
5. Press C-c C-c
6. Wait for the AI response to appear below

** Configuration

You can configure the AI behavior at the file level using these properties:

- =#+AI_SYSTEM:= - System prompt to set AI behavior
- =#+AI_MODEL:= - Specify which model to use
- =#+AI_TEMPERATURE:= - Control randomness (0.0 to 1.0)
- =#+AI_MAX_TOKENS:= - Limit response length
- =#+AI_COMMAND:= - Override which AI CLI to use

** Multi-turn Conversations

#+BEGIN_PROMPT
What's the capital of France?
#+END_PROMPT

#+BEGIN_RESPONSE
The capital of France is Paris.
#+END_RESPONSE

#+BEGIN_PROMPT
What's the population of that city?
#+END_PROMPT

#+BEGIN_RESPONSE
Paris has a population of approximately 2.2 million people within the city limits,
and about 12 million in the greater metropolitan area (ÃŽle-de-France region).
#+END_RESPONSE

* Advanced Usage

** Custom Adapters

You can create custom adapters for any AI CLI tool. Here's an example:

#+BEGIN_SRC elisp
(defun my-custom-ai-adapter (messages system-prompt model temperature max-tokens)
  "Custom adapter for my-ai-tool."
  (let ((args '("chat" "--json")))
    (when model
      (setq args (append args (list "--model" model))))
    ;; Format messages as JSON and pass to tool
    (append args (list (json-encode messages)))))

;; Use it
(setq org-ai-prompt-args-function 'my-custom-ai-adapter)
#+END_SRC

** Different AI Tools in Different Files

Each org file can specify its own AI command:

In file1.org:
: #+AI_COMMAND: claude

In file2.org:
: #+AI_COMMAND: gemini

In file3.org:
: #+AI_COMMAND: /usr/local/bin/my-custom-ai-wrapper.sh
